{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "# face and eyes are templates from opencv\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_files/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_files/haarcascade_eye.xml')\n",
    "distract_model = load_model('distraction_model.hdf5', compile=False)\n",
    "emotion_model_path = '_mini_XCEPTION.72-0.64.hdf5'\n",
    "img_path = sys.argv[1]\n",
    "detection_model_path = 'hc_ff_d.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame params\n",
    "frame_w = 720\n",
    "border_w = 2\n",
    "min_size_w = 240\n",
    "min_size_h = 240\n",
    "min_size_w_eye = 60\n",
    "min_size_h_eye = 60\n",
    "scale_factor = 1.1\n",
    "min_neighbours = 5\n",
    "# image iterators\n",
    "# i = image filename number\n",
    "# j = controls how often images should be saved\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "# hyper-parameters for bounding boxes shape\n",
    "# loading models\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = [\"angry\",\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video writer\n",
    "# IMPORTANT:\n",
    "# - frame width and height must match output frame shape\n",
    "# - avi works on ubuntu. mp4 doesn't :/\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "video_out = cv2.VideoWriter('video_out.avi', fourcc, 10.0,(1200, 900))\n",
    "\n",
    "#reading the frame\n",
    "orig_frame = cv2.imread(img_path)\n",
    "eframe = cv2.imread(img_path,0)\n",
    "efaces = face_detection.detectMultiScale(eframe,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# init camera window\n",
    "cv2.namedWindow('Concentration Analysis')\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (camera.isOpened() == False): \n",
    "    print(\"Unable to read camera feed\")\n",
    "    \n",
    "counter = 0\n",
    "frame_array = []\n",
    "conc_array = []\n",
    "fig = plt.figure('Concentration Graph')\n",
    "\n",
    "\n",
    "#ax1 = plt.subplot(1,1,1)\n",
    "\n",
    "while True:\n",
    "    # get frame\n",
    "    ret, frame = camera.read() \n",
    "   \n",
    "    counter += 1\n",
    "\n",
    "    # if we have a frame, do stuff\n",
    "    if ret:\n",
    "        \n",
    "        canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
    "        frameClone = frame.copy()\n",
    "\n",
    "        # make frame bigger\n",
    "        frame = imutils.resize(frame, width=frame_w)\n",
    "\n",
    "        # use grayscale for faster processing\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect face(s)\n",
    "        faces = face_cascade.detectMultiScale(gray,scaleFactor=scale_factor,minNeighbors=min_neighbours,minSize=(min_size_w,min_size_h),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        # for each face, detect eyes and distraction\n",
    "        if len(faces) > 0:\n",
    "\n",
    "            # loop through faces\n",
    "            for (x,y,w,h) in faces:\n",
    "                # draw face rectangle\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                # get gray face for eye detection\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                # get colour face for distraction detection (model has 3 input channels - probably redundant)\n",
    "                roi_color = frame[y:y+h, x:x+w]\n",
    "                # detect gray eyes\n",
    "                eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=scale_factor,minNeighbors=min_neighbours,minSize=(min_size_w_eye,min_size_w_eye))\n",
    "\n",
    "                # init probability list for each eye prediction\n",
    "                probs = list()\n",
    "\n",
    "                # loop through detected eyes\n",
    "                for (ex,ey,ew,eh) in eyes:\n",
    "                    # draw eye rectangles\n",
    "                    cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),border_w)\n",
    "                    # get colour eye for distraction detection\n",
    "                    roi = roi_color[ey+border_w:ey+eh-border_w, ex+border_w:ex+ew-border_w]\n",
    "                    # match CNN input shape\n",
    "                    roi = cv2.resize(roi, (64, 64))\n",
    "                    # normalize (as done in model training)\n",
    "                    roi = roi.astype(\"float\") / 255.0\n",
    "                    # change to array\n",
    "                    roi = img_to_array(roi)\n",
    "                    # correct shape\n",
    "                    roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "                    # distraction classification/detection\n",
    "                    prediction = distract_model.predict(roi)\n",
    "                    # save eye result\n",
    "                    probs.append(prediction[0])\n",
    "\n",
    "                # get average score for all eyes\n",
    "                probs_mean = np.mean(probs)\n",
    "\n",
    "                # get label\n",
    "                if probs_mean <= 0.5:\n",
    "                    label = 'distracted'\n",
    "                else:\n",
    "                    label = 'focused'\n",
    "\n",
    "                # insert label on frame\n",
    "                cv2.putText(frame,label,(x,y-5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, (0,0,255), 3, cv2.LINE_AA)\n",
    "        #else: continue\n",
    "\n",
    "        efaces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        if len(efaces) > 0:\n",
    "            efaces = sorted(efaces, reverse=True,\n",
    "            key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "            (fX, fY, fW, fH) = efaces\n",
    "                        # Extract the ROI of the face from the grayscale image, resize it to a fixed 48x48 pixels, and then prepare\n",
    "                # the ROI for classification via the CNN\n",
    "            eroi = gray[fY:fY + fH, fX:fX + fW]\n",
    "            eroi = cv2.resize(eroi, (48, 48))\n",
    "            eroi = eroi.astype(\"float\") / 255.0\n",
    "            eroi = img_to_array(eroi)\n",
    "            eroi = np.expand_dims(eroi, axis=0)\n",
    "\n",
    "            preds = emotion_classifier.predict(eroi)[0]\n",
    "            emotion_probability = np.max(preds)\n",
    "            elabel = EMOTIONS[preds.argmax()]   \n",
    "        else: continue\n",
    "\n",
    "        for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "                # construct the label text\n",
    "                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
    "                w = int(prob * 300)\n",
    "                cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
    "                (w, (i * 35) + 35), (0, 0, 255), -1)\n",
    "                cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
    "                (255, 255, 255), 2)\n",
    "                cv2.putText(frameClone, elabel, (fX, fY - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "                cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "        if probs_mean > 0.5:\n",
    "            if elabel == 'neutral':\n",
    "                perconc = (emotion_probability*0.9) * 100\n",
    "            elif elabel == 'happy':\n",
    "                perconc = (emotion_probability*0.6) * 100\n",
    "            elif elabel == 'surprised':\n",
    "                perconc = (emotion_probability*0.5) * 100\n",
    "            elif elabel == 'sad':\n",
    "                perconc = (emotion_probability*0.3) * 100\n",
    "            elif elabel == 'scared':\n",
    "                perconc = (emotion_probability*0.3) * 100\n",
    "            elif elabel == 'angry':\n",
    "                perconc = (emotion_probability*0.25) * 100\n",
    "            elif elabel == 'disgust':\n",
    "                perconc = (emotion_probability*0.2) * 100\n",
    "        elif not ret:\n",
    "            perconc = 0\n",
    "        else:\n",
    "            perconc = 0\n",
    "\n",
    "        frame_array.append(counter)\n",
    "        conc_array.append(perconc)\n",
    "        fig.suptitle('Concentration Graph')\n",
    "        plt.ylabel('Concentration (%)')\n",
    "        plt.xlabel('Frames')\n",
    "        plt.plot(frame_array, conc_array)\n",
    "\n",
    "        plt.show()\n",
    "        plt.pause(0.0001) #Note this correction\n",
    "\n",
    "        # Write the frame to video\n",
    "        video_out.write(frame)\n",
    "\n",
    "        # display frame in window\n",
    "        cv2.imshow('Concentration Analysis', frame)   \n",
    "        cv2.imshow(\"Probabilities\", canvas)\n",
    "        \n",
    "        with open('data.txt','w') as writeFile:\n",
    "            writer = csv.writer(writeFile)\n",
    "            writer.writerow(conc_array)\n",
    "        \n",
    "        \n",
    "        # quit with q\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            camera.release()\n",
    "            video_out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    \n",
    "    # no frame, don't do stuff\n",
    "    else:\n",
    "        perconc = 0\n",
    "        continue\n",
    "        #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close\n",
    "camera.release()\n",
    "video_out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
